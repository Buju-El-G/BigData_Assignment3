# -*- coding: utf-8 -*-
"""Spark K-Means Clustering Script (Task 6)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NMDg6Xo2OcgxJfpC-sWnEUvZf4E8t6zY
"""

# clustering_spark.py (Task 6 - Analysis Fix)
import time
import warnings
import logging
import traceback
from pathlib import Path

# Import Spark specific modules
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.window import Window
from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, IndexToString, StringIndexerModel
from pyspark.ml.clustering import KMeans, KMeansModel
from pyspark.ml.pipeline import Pipeline, PipelineModel # Import PipelineModel

# --- Configuration ---
# Path where the cleaned Parquet files are located (output from Phase 2)
CLEANED_PATH = "/home/bigdata/amazon_data_cleaned"
parquet_file_pattern = str(Path(CLEANED_PATH) / "*_cleaned.parquet")
# Output directory for this script's results
OUTPUT_DIR = Path("./spark_clustering_results")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Log file configuration
LOG_FILE = OUTPUT_DIR / "clustering_spark.log"
# Pipeline Model save path (feature engineering pipeline)
PIPELINE_MODEL_PATH = str(OUTPUT_DIR / "feature_pipeline_model") # Save the feature pipeline too
# KMeans Model save path
KMEANS_MODEL_PATH = str(OUTPUT_DIR / "kmeans_model")
# Cluster Analysis Results save path
RESULTS_FILE = OUTPUT_DIR / "clustering_results.txt"

# Spark Configuration
SPARK_DRIVER_MEMORY = "28g"
SPARK_EXECUTOR_MEMORY = "28g"
SPARK_KRYO_BUFFER_MAX = "512m"

# Clustering Configuration
NUM_CLUSTERS = 5
KMEANS_SEED = 37
TOP_N_CATEGORICAL = 3 # Show top N brands/categories per cluster
# --- End Configuration ---

# --- Setup Logging ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, mode='a'),
        logging.StreamHandler()
    ]
)

logging.info("="*50)
logging.info("Script execution started.")
logging.info("Starting Task 6: K-Means Clustering using PySpark...")
script_start_time = time.time()

# --- Initialize Spark Session ---
logging.info("Initializing Spark Session...")
spark = None
try:
    spark = SparkSession.builder \
        .appName("KMeansClustering") \
        .config("spark.driver.memory", SPARK_DRIVER_MEMORY) \
        .config("spark.executor.memory", SPARK_EXECUTOR_MEMORY) \
        .config("spark.sql.parquet.enableVectorizedReader", "true") \
        .config("spark.sql.execution.arrow.pyspark.enabled", "true") \
        .config("spark.kryoserializer.buffer.max", SPARK_KRYO_BUFFER_MAX) \
        .master("local[*]") \
        .getOrCreate()
    logging.info(f"Spark Session created. Spark version: {spark.version}")
    logging.info(f"Spark Web UI available at: {spark.sparkContext.uiWebUrl}")
    logging.info(f"Driver Memory: {SPARK_DRIVER_MEMORY}, Executor Memory: {SPARK_EXECUTOR_MEMORY}")
    logging.info(f"Kryo max buffer set to: {SPARK_KRYO_BUFFER_MAX}")
except Exception as e:
    logging.error(f"Fatal Error creating Spark Session: {e}")
    logging.error(traceback.format_exc())
    exit()

# --- Load and Prepare Data ---
df_clust = None
pipelineModel = None
kmeansModel = None
predictions = None
try:
    logging.info(f"Loading data from: {parquet_file_pattern}")
    required_cols = ["parent_asin", "rating", "brand", "main_category"]
    df_load = spark.read.parquet(parquet_file_pattern).select(*required_cols)
    df_load = df_load.dropna(subset=["parent_asin", "rating"])
    df_load = df_load.fillna("Unknown", subset=["brand", "main_category"])
    initial_count = df_load.count()
    logging.info(f"Loaded {initial_count} rows with required columns.")
    if initial_count == 0: raise ValueError("No valid rows found after loading.")

    logging.info("Aggregating features by product (parent_asin)...")
    df_agg = df_load.groupBy("parent_asin").agg(
        F.mean("rating").alias("mean_rating"),
        F.count("*").alias("total_reviews")
    )
    df_meta_distinct = df_load.select("parent_asin", "brand", "main_category").dropDuplicates(["parent_asin"])
    df_features_raw = df_agg.join(df_meta_distinct, on="parent_asin", how="inner")
    product_count = df_features_raw.count()
    logging.info(f"Aggregation complete. Number of unique products: {product_count}")
    if product_count == 0: raise ValueError("No products found after aggregation/join.")

    logging.info("Setting up feature engineering pipeline (Indexing, Scaling, Assembling)...")
    brandIndexer = StringIndexer(inputCol="brand", outputCol="brand_id", handleInvalid="keep")
    categoryIndexer = StringIndexer(inputCol="main_category", outputCol="category_id", handleInvalid="keep")
    numFeatAssembler = VectorAssembler(inputCols=["mean_rating", "total_reviews"], outputCol="numFeatures")
    scaler = StandardScaler(inputCol="numFeatures", outputCol="scaledNumFeatures", withStd=True, withMean=True)
    finalAssembler = VectorAssembler(inputCols=["scaledNumFeatures", "brand_id", "category_id"], outputCol="features")
    featurePipeline = Pipeline(stages=[brandIndexer, categoryIndexer, numFeatAssembler, scaler, finalAssembler])

    logging.info("Fitting feature engineering pipeline...")
    start_fit_pipe = time.time()
    pipelineModel = featurePipeline.fit(df_features_raw)
    logging.info(f"Pipeline fitting complete. Time: {time.time() - start_fit_pipe:.2f}s")

    # --- Save the Feature Pipeline Model (includes indexers) ---
    logging.info(f"Saving feature pipeline model to: {PIPELINE_MODEL_PATH}")
    pipelineModel.write().overwrite().save(PIPELINE_MODEL_PATH)
    logging.info("Feature pipeline model saved.")

    logging.info("Transforming data with feature pipeline...")
    df_clust = pipelineModel.transform(df_features_raw)
    logging.info("Data transformed with feature vector.")
    df_clust.select("parent_asin", "features").show(5, truncate=False)
    df_clust.cache()
    prep_count = df_clust.count()
    logging.info(f"Featured data count: {prep_count}. Data cached.")

    # --- K-Means Clustering ---
    logging.info(f"Training KMeans model (k={NUM_CLUSTERS})...")
    start_train = time.time()
    kmeans = KMeans(featuresCol="features", k=NUM_CLUSTERS, seed=KMEANS_SEED)
    kmeansModel = kmeans.fit(df_clust)
    end_train = time.time()
    logging.info(f"KMeans model training complete. Time: {end_train - start_train:.2f}s")

    # Log WCSS (Cost)
    wcss = kmeansModel.summary.trainingCost
    logging.info(f"Within Set Sum of Squared Errors (WCSS) = {wcss}")

    # --- Save the KMeans Model ---
    logging.info(f"Saving KMeans model to: {KMEANS_MODEL_PATH}")
    kmeansModel.write().overwrite().save(KMEANS_MODEL_PATH)
    logging.info("KMeans model saved successfully.")

    # --- Assign Clusters ---
    logging.info("Assigning clusters to products...")
    predictions = kmeansModel.transform(df_clust)
    # Rename prediction column for clarity
    predictions = predictions.withColumnRenamed("prediction", "cluster_id")
    predictions.select("parent_asin", "features", "cluster_id").show(5, truncate=False)
    predictions.cache()
    pred_count = predictions.count()
    logging.info(f"Cluster assignments complete. Count: {pred_count}")

except Exception as e:
    logging.error(f"Fatal Error during Feature Engineering or K-Means training: {e}")
    logging.error(traceback.format_exc())
    if spark: spark.stop()
    exit()


# --- Cluster Analysis ---
cluster_analysis_results = {} # Dictionary to hold results per cluster
try:
    logging.info("Analyzing cluster characteristics...")
    start_analysis = time.time()

    # Calculate numerical summaries per cluster
    logging.info("Calculating numerical summaries per cluster...")
    numerical_summary = predictions.groupBy("cluster_id").agg(
        F.count("*").alias("cluster_size"),
        F.mean("mean_rating").alias("avg_mean_rating"),
        F.mean("total_reviews").alias("avg_total_reviews")
        # We will calculate avg Brand/Category IDs later if needed,
        # but top strings are more interpretable
    ).orderBy("cluster_id")
    logging.info("Numerical summaries calculated.")
    numerical_summary.show(truncate=False)

    # Collect numerical summaries for saving
    summary_list = numerical_summary.collect()
    for row in summary_list:
        cluster_id = row['cluster_id']
        cluster_analysis_results[cluster_id] = {
            "cluster_size": row['cluster_size'],
            "avg_mean_rating": row['avg_mean_rating'],
            "avg_total_reviews": row['avg_total_reviews'],
            "top_brands": [], # Initialize lists
            "top_categories": []
        }

    # --- Find dominant brand/category strings per cluster ---
    # Need to map indices back to strings first
    logging.info("Finding dominant brand/category strings per cluster...")

    # Create IndexToString transformers using the fitted StringIndexer models from the pipeline
    brand_indexer_model = pipelineModel.stages[0] # Assuming brandIndexer was the first stage
    category_indexer_model = pipelineModel.stages[1] # Assuming categoryIndexer was second

    brandConverter = IndexToString(inputCol="brand_id", outputCol="brand_str", labels=brand_indexer_model.labels)
    categoryConverter = IndexToString(inputCol="category_id", outputCol="category_str", labels=category_indexer_model.labels)

    clustered_df_labeled = brandConverter.transform(predictions)
    clustered_df_labeled = categoryConverter.transform(clustered_df_labeled)
    logging.info("Converted brand/category IDs back to strings.")

    # Define window spec for ranking within each cluster
    windowSpec = Window.partitionBy("cluster_id").orderBy(F.col("count").desc()) # *** Use 'count' here ***

    # Find top N brands per cluster
    logging.info(f"Finding top {TOP_N_CATEGORICAL} brands per cluster...")
    dominant_brands = clustered_df_labeled.groupBy("cluster_id", "brand_str").count() \
        .withColumn("rank", F.row_number().over(windowSpec)) \
        .filter(F.col("rank") <= TOP_N_CATEGORICAL) \
        .orderBy("cluster_id", "rank") \
        .select("cluster_id", "brand_str", "count")

    logging.info("Top brands per cluster:")
    dominant_brands.show(NUM_CLUSTERS * TOP_N_CATEGORICAL, truncate=False)
    # Collect results and add to dictionary
    for row in dominant_brands.collect():
        cluster_id = row['cluster_id']
        if cluster_id in cluster_analysis_results:
             cluster_analysis_results[cluster_id]["top_brands"].append(f"{row['brand_str']} ({row['count']})")

    # Find top N categories per cluster
    logging.info(f"Finding top {TOP_N_CATEGORICAL} categories per cluster...")
    dominant_categories = clustered_df_labeled.groupBy("cluster_id", "category_str").count() \
        .withColumn("rank", F.row_number().over(windowSpec.partitionBy("cluster_id").orderBy(F.col("count").desc()))) \
        .filter(F.col("rank") <= TOP_N_CATEGORICAL) \
        .orderBy("cluster_id", "rank") \
        .select("cluster_id", "category_str", "count")

    logging.info("Top categories per cluster:")
    dominant_categories.show(NUM_CLUSTERS * TOP_N_CATEGORICAL, truncate=False)
    # Collect results and add to dictionary
    for row in dominant_categories.collect():
        cluster_id = row['cluster_id']
        if cluster_id in cluster_analysis_results:
             cluster_analysis_results[cluster_id]["top_categories"].append(f"{row['category_str']} ({row['count']})")

    end_analysis = time.time()
    logging.info(f"Cluster analysis complete. Time: {end_analysis - start_analysis:.2f}s")

    # --- Save Cluster Analysis Results ---
    logging.info(f"Saving cluster analysis results to: {RESULTS_FILE}")
    with open(RESULTS_FILE, 'w') as f:
        f.write(f"KMeans Cluster Analysis (k={NUM_CLUSTERS})\n")
        f.write("-----------------------------\n")
        f.write(f"WCSS (Training Cost): {wcss}\n\n")
        # Sort clusters by ID for consistent output
        for cluster_id in sorted(cluster_analysis_results.keys()):
            results = cluster_analysis_results[cluster_id]
            f.write(f"Cluster {cluster_id}:\n")
            f.write(f"  Size: {results['cluster_size']}\n")
            f.write(f"  Avg Mean Rating: {results['avg_mean_rating']:.2f}\n")
            f.write(f"  Avg Total Reviews: {results['avg_total_reviews']:.1f}\n")
            f.write(f"  Top {TOP_N_CATEGORICAL} Brands: {', '.join(results['top_brands'])}\n")
            f.write(f"  Top {TOP_N_CATEGORICAL} Categories: {', '.join(results['top_categories'])}\n")
            f.write("\n")
        f.write("\nInterpretation: [Provide interpretation for each cluster based on the averages and top brands/categories...]\n")
    logging.info("Cluster analysis results saved successfully.")

except Exception as e:
    logging.error(f"An error occurred during K-Means training or analysis: {e}")
    logging.error(traceback.format_exc())

# --- Cleanup ---
finally:
    logging.info("Cleaning up cached dataframes...")
    if df_clust: df_clust.unpersist()
    if predictions: predictions.unpersist()
    logging.info("Unpersisted cached data.")

    logging.info("Stopping Spark Session...")
    if spark: spark.stop()
    logging.info("Spark Session stopped.")

script_end_time = time.time()
total_time = script_end_time - script_start_time
logging.info(f"--- K-Means Clustering (Task 6 using Spark) Completed ---")
logging.info(f"Total script time taken: {total_time:.2f} seconds ({total_time / 3600:.2f} hours)")
print(f"\n--- K-Means Clustering (Task 6 using Spark) Completed ---") # Final confirmation
print(f"Total time taken: {total_time:.2f} seconds")