# -*- coding: utf-8 -*-
"""EDA Script (Dask) - Plot Fixes

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jxww4a4lfg1d76l__5JX65pggC9W2XmP
"""

# eda_analysis.py (v2 - Plot Fixes)
import dask.dataframe as dd
import pandas as pd
import matplotlib
# Use Agg backend for non-interactive saving in server environments
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import time
import warnings

# Ignore specific warnings if needed (e.g., from Dask or plotting libraries)
warnings.filterwarnings("ignore", category=FutureWarning)

# --- Configuration ---
# Path where the cleaned Parquet files are located
CLEANED_PATH = Path("/home/bigdata/amazon_data_cleaned")
# Path where plots will be saved
PLOTS_PATH = Path("/home/bigdata/BigData_A3/eda_plots")
# Create the plots directory if it doesn't exist
PLOTS_PATH.mkdir(parents=True, exist_ok=True)

# Define the path pattern for input files
parquet_file_pattern = str(CLEANED_PATH / "*_cleaned.parquet")
# --- End Configuration ---

print("Starting EDA Analysis using Dask...")
start_time = time.time()

# --- Load Data with Dask ---
print(f"Loading data from: {parquet_file_pattern}")
try:
    ddf = dd.read_parquet(parquet_file_pattern)
    print("Data loaded as Dask DataFrame.")
    # Calculate and print row count immediately after load if needed
    # total_rows = len(ddf) # This triggers computation
    # print(f"Total rows (computed): {total_rows}")
except Exception as e:
    print(f"Error loading data with Dask: {e}")
    print("Please ensure Parquet files exist and Dask is installed correctly.")
    exit()

# Print basic info (schema is cheap, columns list is cheap)
print(f"Columns: {list(ddf.columns)}")
print("Data types:\n", ddf.dtypes)

# --- EDA Task 3a: Star Rating Histogram ---
print("\n--- Task 3a: Star Rating Distribution ---")
try:
    print("Calculating rating distribution...")
    rating_counts = ddf['rating'].value_counts().compute()
    rating_counts = rating_counts.sort_index()
    print("Rating counts computed.")

    fig, ax = plt.subplots(figsize=(8, 5)) # Use fig, ax pattern
    sns.barplot(x=rating_counts.index, y=rating_counts.values, palette='viridis', ax=ax)
    ax.set_title('Distribution of Star Ratings')
    ax.set_xlabel('Rating')
    ax.set_ylabel('Number of Reviews')
    plot_path = PLOTS_PATH / "a_rating_histogram.png"
    plt.savefig(plot_path)
    plt.close(fig) # Close the figure to free memory
    print(f"Plot saved to: {plot_path}")
    print("Interpretation: [Describe the shape - e.g., J-shaped with peaks at 5 and 1 stars? What does this imply about user review tendencies?]")
except Exception as e:
    print(f"Error during rating histogram: {e}")
    traceback.print_exc() # Print traceback for plotting errors

# --- EDA Task 3b: Top 10 Categories ---
print("\n--- Task 3b: Top 10 Categories ---")
try:
    if 'main_category' in ddf.columns:
        print("Calculating top 10 categories...")
        top_categories = ddf['main_category'].value_counts().nlargest(10).compute()
        print("Top categories computed.")

        fig, ax = plt.subplots(figsize=(12, 6))
        sns.barplot(x=top_categories.index, y=top_categories.values, palette='mako', ax=ax)
        ax.set_title('Top 10 Product Categories by Review Count')
        ax.set_xlabel('Category')
        ax.set_ylabel('Number of Reviews')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plot_path = PLOTS_PATH / "b_top_categories.png"
        plt.savefig(plot_path)
        plt.close(fig)
        print(f"Plot saved to: {plot_path}")
        print("Interpretation: [Which categories dominate the dataset? Are they expected (e.g., Electronics, Books)?]")
    else:
        print("'main_category' column not found.")
except Exception as e:
    print(f"Error during top categories analysis: {e}")
    traceback.print_exc()

# --- EDA Task 3c: Top 10 Brands ---
print("\n--- Task 3c: Top 10 Brands ---")
try:
    if 'brand' in ddf.columns:
        print("Filtering out 'Unknown' brand and finding top 10...")
        ddf_known_brands = ddf[ddf['brand'] != 'Unknown']
        top_brands = ddf_known_brands['brand'].value_counts().nlargest(10).compute()

        # *** ADDED PRINT STATEMENT FOR DIAGNOSTICS ***
        print("Top 10 Brands (excluding Unknown):")
        print(top_brands)
        print("-" * 30)

        if not top_brands.empty: # Only plot if there are brands
            fig, ax = plt.subplots(figsize=(12, 6))
            sns.barplot(x=top_brands.index, y=top_brands.values, palette='rocket', ax=ax)
            ax.set_title('Top 10 Brands by Review Count (Excluding "Unknown")')
            ax.set_xlabel('Brand')
            ax.set_ylabel('Number of Reviews')
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            plot_path = PLOTS_PATH / "c_top_brands.png"
            plt.savefig(plot_path)
            plt.close(fig)
            print(f"Plot saved to: {plot_path}")
            print("Interpretation: [Which brands have the most reviews? Are they major manufacturers or perhaps Amazon-specific brands?]")
        else:
            print("No known brands found after filtering 'Unknown'. Plot not generated.")
    else:
        print("'brand' column not found.")
except Exception as e:
    print(f"Error during top brands analysis: {e}")
    traceback.print_exc()

# --- EDA Task 3d: Time-Based Trend (Average Rating per Year) ---
print("\n--- Task 3d: Average Rating per Year ---")
try:
    if 'year' in ddf.columns and 'rating' in ddf.columns:
        print("Calculating average rating per year...")
        # Drop rows with invalid years before grouping
        # Also convert year to int for cleaner grouping/plotting
        # Using meta_like to help Dask infer output type after apply
        ddf_filtered_year = ddf[['year', 'rating']].dropna(subset=['year'])
        ddf_filtered_year['year'] = ddf_filtered_year['year'].astype(int) # Convert to int

        yearly_avg_rating = ddf_filtered_year.groupby('year')['rating'].mean().compute()
        yearly_avg_rating = yearly_avg_rating.sort_index()
        print("Average ratings computed.")

        # Filter out potential outlier years (e.g., very old or future years)
        current_year = pd.Timestamp.now().year
        yearly_avg_rating = yearly_avg_rating[(yearly_avg_rating.index >= 1995) & (yearly_avg_rating.index <= current_year)]
        print(f"Filtered years to range 1995-{current_year}")

        if not yearly_avg_rating.empty:
            fig, ax = plt.subplots(figsize=(12, 6))
            yearly_avg_rating.plot(kind='line', marker='o', linestyle='-', ax=ax)
            ax.set_title('Average Star Rating per Year')
            ax.set_xlabel('Year')
            ax.set_ylabel('Average Rating')
            ax.grid(True)
            plt.tight_layout()
            plot_path = PLOTS_PATH / "d_avg_rating_per_year.png"
            plt.savefig(plot_path)
            plt.close(fig)
            print(f"Plot saved to: {plot_path}")
            print("Interpretation: [Describe the trend...]")
        else:
             print("No valid yearly average rating data found after filtering.")
    else:
        print("'year' or 'rating' column not found.")
except Exception as e:
    print(f"Error during time-based trend analysis: {e}")
    traceback.print_exc()

# --- EDA Task 3e: Correlation: Review Length vs. Star Rating ---
print("\n--- Task 3e: Correlation (Review Length vs. Rating) ---")
review_length_rating_corr = None # Initialize
try:
    if 'review_length' in ddf.columns and 'rating' in ddf.columns:
        print("Calculating correlation based on a 10% sample...")
        sample_fraction = 0.1
        ddf_corr_sample = ddf[['review_length', 'rating']].dropna().sample(frac=sample_fraction)
        df_corr_sample_pd = ddf_corr_sample.compute()
        print(f"Computed sample of size {len(df_corr_sample_pd)}")

        if not df_corr_sample_pd.empty:
            correlation_matrix = df_corr_sample_pd.corr(method='pearson')
            review_length_rating_corr = correlation_matrix.loc['review_length', 'rating']
            print(f"Sample-based Pearson Correlation between Review Length and Star Rating: {review_length_rating_corr:.4f}")
            print("Interpretation: [Interpret the result... Acknowledge this is based on a sample.]")

            # *** UNCOMMENTED SCATTER PLOT CODE ***
            print("Generating scatter plot based on a smaller 0.1% sample...")
            # Use a smaller fraction for scatter plot to avoid overplotting and slow computation
            scatter_sample_fraction = 0.001
            # Ensure we sample from the original ddf to get a fresh sample
            scatter_sample_dd = ddf[['review_length', 'rating']].dropna().sample(frac=scatter_sample_fraction)
            scatter_sample_pd = scatter_sample_dd.compute()
            print(f"Computed scatter sample of size {len(scatter_sample_pd)}")

            if not scatter_sample_pd.empty:
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.scatterplot(data=scatter_sample_pd, x='review_length', y='rating', alpha=0.1, ax=ax) # Use alpha for density
                ax.set_title('Scatter Plot: Rating vs Review Length (0.1% Sample)')
                ax.set_xlabel('Review Length (Tokens)')
                ax.set_ylabel('Rating')
                ax.set_xscale('log') # Use log scale if review length distribution is skewed
                plot_path = PLOTS_PATH / "e_scatter_rating_length.png"
                plt.savefig(plot_path)
                plt.close(fig) # Close figure
                print(f"Scatter plot saved to: {plot_path}")
            else:
                print("Scatter plot sample was empty. Plot not generated.")
        else:
            print("Correlation sample was empty. Correlation not calculated.")
    else:
        print("'review_length' or 'rating' column not found.")
except Exception as e:
    print(f"Error during correlation analysis: {e}")
    traceback.print_exc()


# --- Analysis Completion ---
end_time = time.time()
print(f"\n--- EDA Analysis Completed ---")
print(f"Total time taken: {end_time - start_time:.2f} seconds")
print(f"Plots saved in: {PLOTS_PATH}")
# Also print correlation value at the end if calculated
if review_length_rating_corr is not None:
    print(f"Final Sampled Correlation (Rating vs Length): {review_length_rating_corr:.4f}")