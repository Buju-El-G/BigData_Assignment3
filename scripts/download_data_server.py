# -*- coding: utf-8 -*-
"""download_data_server.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AB92ryhEKCzwI6KgU6hPiFDGC3KFWqBT
"""

# download_data_server.py
import os
from pathlib import Path
import random # Import random if you want to shuffle

# Import necessary functions from the utility script
# Make sure bigdata_a3_utils.py is in the same directory or accessible
try:
    from bigdata_a3_utils import download_all_amazon_reviews, get_cache_directory, delete_cache_directory, VALID_CATEGORIES
except ImportError:
    print("Error: Could not import from bigdata_a3_utils.py.")
    print("Please ensure bigdata_a3_utils.py is in the same directory as this script.")
    exit()

# --- Configuration ---
# *** Set this to your desired data directory ON THE SERVER ***
# Using '/home/bigdata/' as an example base - adjust if needed
# Creates a directory named 'amazon_data_uncompressed' in the user's home directory
SAVE_PATH = Path("/home/bigdata/amazon_data_uncompressed")

# --- Define Download Order (Optional) ---
# Option A: Download all categories in a specific custom order
# custom_category_order = ["Electronics", "Books", "Clothing_Shoes_and_Jewelry", "Home_and_Kitchen", ...] # Add all VALID_CATEGORIES here

# Option B: Download all categories in a random order
# categories_to_download = VALID_CATEGORIES.copy()
# random.shuffle(categories_to_download)

# Option C: Download only a subset for testing
# categories_to_download = VALID_CATEGORIES[:3]

# Option D: Default - Download all in the predefined order (same as passing None)
categories_to_download = [ "Video_Games", "Unknown", "Toys_and_Games", "Tools_and_Home_Improvement", "Subscription_Boxes",
"Sports_and_Outdoors", "Software", "Pet_Supplies", "Patio_Lawn_and_Garden", "Office_Products",
"Musical_Instruments", "Movies_and_TV", "Magazine_Subscriptions", "Kindle_Store", "Industrial_and_Scientific",
"Home_and_Kitchen", "Health_and_Personal_Care", "Health_and_Household", "Handmade_Products", "Grocery_and_Gourmet_Food",
"Gift_Cards", "Electronics", "Digital_Music", "Clothing_Shoes_and_Jewelry", "Cell_Phones_and_Accessories",
"CDs_and_Vinyl", "Books", "Beauty_and_Personal_Care", "Baby_Products", "Automotive",
"Arts_Crafts_and_Sewing", "Appliances", "Amazon_Fashion", "All_Beauty" ]

# --- End Configuration ---

# Print status messages
print(f"Starting download to: {SAVE_PATH}")
print("Downloading data UNCOMPRESSED.") # Note: Changed from compressed
if isinstance(categories_to_download, list):
    print(f"Attempting to download {len(categories_to_download)} categories in specified order.")
else:
    print("Attempting to download all categories in default order.")


# Ensure the save path directory exists; create it if it doesn't
SAVE_PATH.mkdir(parents=True, exist_ok=True)

# Display the Hugging Face cache directory (for information)
# This cache will also be stored on the server, likely in /home/bigdata/.cache/huggingface/
get_cache_directory()

# Try to download the data
try:
    download_all_amazon_reviews(
        base_save_path=SAVE_PATH,
        categories=categories_to_download, # Pass your defined list or None
        compress=False,   # *** Set to False for uncompressed download ***
        # compression_format and compression_level are ignored when compress=False
    )
    print("\nDownload process finished.")
    # Optional: Clean HF cache after download if needed
    # print("Cleaning Hugging Face cache...")
    # delete_cache_directory()
    # print("Cache cleaned.")

# Handle potential errors during setup or download
except ValueError as ve:
    print(f"\nError during setup: {ve}")
    print("Please check your SAVE_PATH and ensure it's not overlapping with the cache.")
except Exception as e:
    print(f"\nAn error occurred during download: {e}")

# Final message indicating where data was saved
print(f"Data saved in uncompressed format at: {SAVE_PATH}")
print("Each category's review/meta data is in its own subfolder (e.g., raw_review_Books/, raw_meta_Books/).")