# -*- coding: utf-8 -*-
"""Spark K-Means Clustering Script (No Brand Feature)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18nLctCva86r3cYR02UzYQs6kgVJsUBB4
"""

# clustering_spark.py (Task 6 - No Brand Feature)
import time
import warnings
import logging
import traceback
from pathlib import Path

# Import Spark specific modules
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.window import Window
# Import ML modules needed
from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, IndexToString, StringIndexerModel
from pyspark.ml.clustering import KMeans, KMeansModel
from pyspark.ml.pipeline import Pipeline, PipelineModel

# --- Configuration ---
# Path where the cleaned Parquet files are located (output from Phase 2)
CLEANED_PATH = "/home/bigdata/amazon_data_cleaned"
parquet_file_pattern = str(Path(CLEANED_PATH) / "*_cleaned.parquet")
# Output directory for this script's results
OUTPUT_DIR = Path("./spark_clustering_results_no_brand") # New output dir
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Log file configuration
LOG_FILE = OUTPUT_DIR / "clustering_spark_no_brand.log"
# Pipeline Model save path (feature engineering pipeline)
PIPELINE_MODEL_PATH = str(OUTPUT_DIR / "feature_pipeline_model_no_brand")
# KMeans Model save path
KMEANS_MODEL_PATH = str(OUTPUT_DIR / "kmeans_model_no_brand")
# Cluster Analysis Results save path
RESULTS_FILE = OUTPUT_DIR / "clustering_results_no_brand.txt"

# Spark Configuration
SPARK_DRIVER_MEMORY = "28g"
SPARK_EXECUTOR_MEMORY = "28g"
SPARK_KRYO_BUFFER_MAX = "512m"

# Clustering Configuration
NUM_CLUSTERS = 5
KMEANS_SEED = 37
TOP_N_CATEGORICAL = 5 # Show top N categories per cluster (increased from 3)
# --- End Configuration ---

# --- Setup Logging ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, mode='a'),
        logging.StreamHandler()
    ]
)

logging.info("="*50)
logging.info("Script execution started.")
logging.info("Starting Task 6: K-Means Clustering (No Brand Feature) using PySpark...") # Updated log
script_start_time = time.time()

# --- Initialize Spark Session ---
logging.info("Initializing Spark Session...")
spark = None
try:
    spark = SparkSession.builder \
        .appName("KMeansClusteringNoBrand") \
        .config("spark.driver.memory", SPARK_DRIVER_MEMORY) \
        .config("spark.executor.memory", SPARK_EXECUTOR_MEMORY) \
        .config("spark.sql.parquet.enableVectorizedReader", "true") \
        .config("spark.sql.execution.arrow.pyspark.enabled", "true") \
        .config("spark.kryoserializer.buffer.max", SPARK_KRYO_BUFFER_MAX) \
        .master("local[*]") \
        .getOrCreate()
    logging.info(f"Spark Session created. Spark version: {spark.version}")
    logging.info(f"Spark Web UI available at: {spark.sparkContext.uiWebUrl}")
    logging.info(f"Driver Memory: {SPARK_DRIVER_MEMORY}, Executor Memory: {SPARK_EXECUTOR_MEMORY}")
    logging.info(f"Kryo max buffer set to: {SPARK_KRYO_BUFFER_MAX}")
except Exception as e:
    logging.error(f"Fatal Error creating Spark Session: {e}")
    logging.error(traceback.format_exc())
    exit()

# --- Load and Prepare Data ---
df_clust = None
pipelineModel = None
kmeansModel = None
predictions = None
try:
    logging.info(f"Loading data from: {parquet_file_pattern}")
    # Load necessary columns - **REMOVED 'brand'**
    required_cols = ["parent_asin", "rating", "main_category"]
    df_load = spark.read.parquet(parquet_file_pattern).select(*required_cols)

    # Handle potential nulls before aggregation/indexing
    df_load = df_load.dropna(subset=["parent_asin", "rating"])
    df_load = df_load.fillna("Unknown", subset=["main_category"]) # Still fill missing category
    logging.info("Filled missing main_category with 'Unknown'.")

    initial_count = df_load.count()
    logging.info(f"Loaded {initial_count} rows with required columns.")
    if initial_count == 0: raise ValueError("No valid rows found after loading.")

    logging.info("Aggregating features by product (parent_asin)...")
    df_agg = df_load.groupBy("parent_asin").agg(
        F.mean("rating").alias("mean_rating"),
        F.count("*").alias("total_reviews")
    )
    logging.info("Aggregation complete.")

    # Get distinct category for each product
    df_meta_distinct = df_load.select("parent_asin", "main_category").dropDuplicates(["parent_asin"])

    # Join aggregated features with distinct metadata
    df_features_raw = df_agg.join(df_meta_distinct, on="parent_asin", how="inner")
    product_count = df_features_raw.count()
    logging.info(f"Joined aggregated features with metadata. Number of unique products: {product_count}")
    if product_count == 0: raise ValueError("No products found after aggregation/join.")

    # --- Feature Engineering Pipeline ---
    logging.info("Setting up feature engineering pipeline (Indexing Category, Scaling, Assembling)...") # Updated log

    # 1. Index categorical column (main_category only)
    categoryIndexer = StringIndexer(inputCol="main_category", outputCol="category_id", handleInvalid="keep")

    # 2. Assemble numerical features for scaling
    numFeatAssembler = VectorAssembler(inputCols=["mean_rating", "total_reviews"], outputCol="numFeatures")

    # 3. Scale numerical features
    scaler = StandardScaler(inputCol="numFeatures", outputCol="scaledNumFeatures", withStd=True, withMean=True)

    # 4. Assemble final feature vector (scaled numerical + indexed categorical) - **REMOVED brand_id**
    finalAssembler = VectorAssembler(inputCols=["scaledNumFeatures", "category_id"], outputCol="features")

    # Create and fit the feature engineering pipeline - **REMOVED brandIndexer**
    featurePipeline = Pipeline(stages=[categoryIndexer, numFeatAssembler, scaler, finalAssembler])
    pipelineModel = featurePipeline.fit(df_features_raw)
    logging.info(f"Pipeline fitting complete.")

    # --- Save the Feature Pipeline Model ---
    logging.info(f"Saving feature pipeline model to: {PIPELINE_MODEL_PATH}")
    pipelineModel.write().overwrite().save(PIPELINE_MODEL_PATH)
    logging.info("Feature pipeline model saved.")

    logging.info("Transforming data with feature pipeline...")
    df_clust = pipelineModel.transform(df_features_raw)
    logging.info("Data transformed with feature vector.")
    df_clust.select("parent_asin", "features").show(5, truncate=False)
    df_clust.cache()
    prep_count = df_clust.count()
    logging.info(f"Featured data count: {prep_count}. Data cached.")

    # --- K-Means Clustering ---
    logging.info(f"Training KMeans model (k={NUM_CLUSTERS})...")
    start_train = time.time()
    kmeans = KMeans(featuresCol="features", k=NUM_CLUSTERS, seed=KMEANS_SEED)
    kmeansModel = kmeans.fit(df_clust)
    end_train = time.time()
    logging.info(f"KMeans model training complete. Time: {end_train - start_train:.2f}s")
    wcss = kmeansModel.summary.trainingCost
    logging.info(f"Within Set Sum of Squared Errors (WCSS) = {wcss}")

    # --- Save the KMeans Model ---
    logging.info(f"Saving KMeans model to: {KMEANS_MODEL_PATH}")
    kmeansModel.write().overwrite().save(KMEANS_MODEL_PATH)
    logging.info("KMeans model saved successfully.")

    # --- Assign Clusters ---
    logging.info("Assigning clusters to products...")
    predictions = kmeansModel.transform(df_clust)
    predictions = predictions.withColumnRenamed("prediction", "cluster_id")
    predictions.select("parent_asin", "features", "cluster_id").show(5, truncate=False)
    predictions.cache()
    pred_count = predictions.count()
    logging.info(f"Cluster assignments complete. Count: {pred_count}")

except Exception as e:
    logging.error(f"Fatal Error during Feature Engineering or K-Means training: {e}")
    logging.error(traceback.format_exc())
    if spark: spark.stop()
    exit()


# --- Cluster Analysis ---
cluster_analysis_results = {}
try:
    logging.info("Analyzing cluster characteristics...")
    start_analysis = time.time()

    # Calculate numerical summaries per cluster
    logging.info("Calculating numerical summaries per cluster...")
    numerical_summary = predictions.groupBy("cluster_id").agg(
        F.count("*").alias("cluster_size"),
        F.mean("mean_rating").alias("avg_mean_rating"),
        F.mean("total_reviews").alias("avg_total_reviews")
    ).orderBy("cluster_id")
    logging.info("Numerical summaries calculated.")
    numerical_summary.show(truncate=False)

    summary_list = numerical_summary.collect()
    for row in summary_list:
        cluster_id = row['cluster_id']
        cluster_analysis_results[cluster_id] = {
            "cluster_size": row['cluster_size'],
            "avg_mean_rating": row['avg_mean_rating'],
            "avg_total_reviews": row['avg_total_reviews'],
            "top_categories": [] # Initialize list
        }

    # --- Find dominant category strings per cluster ---
    logging.info("Finding dominant category strings per cluster...")
    # Load the saved PipelineModel to get the StringIndexerModel for categories
    loadedPipelineModel = PipelineModel.load(PIPELINE_MODEL_PATH)
    # Find the StringIndexerModel for main_category within the loaded pipeline stages
    category_indexer_model = None
    for stage in loadedPipelineModel.stages:
        if isinstance(stage, StringIndexerModel) and stage.getInputCol() == "main_category":
            category_indexer_model = stage
            break
    if not category_indexer_model:
        raise ValueError("Could not find fitted StringIndexerModel for main_category in saved pipeline.")

    categoryConverter = IndexToString(inputCol="category_id", outputCol="category_str", labels=category_indexer_model.labels)
    clustered_df_labeled = categoryConverter.transform(predictions)
    logging.info("Converted category IDs back to strings.")

    windowSpec = Window.partitionBy("cluster_id").orderBy(F.col("count").desc())

    # Find top N categories per cluster
    logging.info(f"Finding top {TOP_N_CATEGORICAL} categories per cluster...")
    dominant_categories = clustered_df_labeled.groupBy("cluster_id", "category_str").count() \
        .withColumn("rank", F.row_number().over(windowSpec)) \
        .filter(F.col("rank") <= TOP_N_CATEGORICAL) \
        .orderBy("cluster_id", "rank") \
        .select("cluster_id", "category_str", "count")

    logging.info("Top categories per cluster:")
    dominant_categories.show(NUM_CLUSTERS * TOP_N_CATEGORICAL, truncate=False)
    # Collect results and add to dictionary
    for row in dominant_categories.collect():
        cluster_id = row['cluster_id']
        if cluster_id in cluster_analysis_results:
             cluster_analysis_results[cluster_id]["top_categories"].append(f"{row['category_str']} ({row['count']})")

    end_analysis = time.time()
    logging.info(f"Cluster analysis complete. Time: {end_analysis - start_analysis:.2f}s")

    # --- Save Cluster Analysis Results ---
    logging.info(f"Saving cluster analysis results to: {RESULTS_FILE}")
    with open(RESULTS_FILE, 'w') as f:
        f.write(f"KMeans Cluster Analysis (k={NUM_CLUSTERS}) - Features: Scaled Rating/Reviews, Category ID\n") # Updated title
        f.write("-------------------------------------------------------------------------------------\n")
        f.write(f"WCSS (Training Cost): {wcss}\n\n")
        for cluster_id in sorted(cluster_analysis_results.keys()):
            results = cluster_analysis_results[cluster_id]
            f.write(f"Cluster {cluster_id}:\n")
            f.write(f"  Size: {results['cluster_size']}\n")
            f.write(f"  Avg Mean Rating: {results['avg_mean_rating']:.2f}\n")
            f.write(f"  Avg Total Reviews: {results['avg_total_reviews']:.1f}\n")
            # Removed Brand info
            f.write(f"  Top {TOP_N_CATEGORICAL} Categories: {', '.join(results['top_categories'])}\n")
            f.write("\n")
        f.write("\nInterpretation: [Provide interpretation for each cluster based on the averages and top categories...]\n") # Updated prompt
    logging.info("Cluster analysis results saved successfully.")

except Exception as e:
    logging.error(f"An error occurred during K-Means training or analysis: {e}")
    logging.error(traceback.format_exc())

# --- Cleanup ---
finally:
    logging.info("Cleaning up cached dataframes...")
    if df_clust: df_clust.unpersist()
    if predictions: predictions.unpersist()
    logging.info("Unpersisted cached data.")

    logging.info("Stopping Spark Session...")
    if spark: spark.stop()
    logging.info("Spark Session stopped.")

script_end_time = time.time()
total_time = script_end_time - script_start_time
logging.info(f"--- K-Means Clustering (Task 6 using Spark - No Brand) Completed ---") # Updated log
logging.info(f"Total script time taken: {total_time:.2f} seconds ({total_time / 3600:.2f} hours)")
print(f"\n--- K-Means Clustering (Task 6 using Spark - No Brand) Completed ---") # Final confirmation
print(f"Total time taken: {total_time:.2f} seconds")